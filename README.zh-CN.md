# ZipRWKV-Speech (Research Stage)

[English](./README.md) | [ä¸­æ–‡ç‰ˆ]

é€™å€‹å°ˆæ¡ˆæ˜¯ä¸€å€‹åŸºæ–¼ LLM çš„èªéŸ³è¾¨è­˜ (SpeechLLM)ï¼Œæ ¸å¿ƒæ¶æ§‹æ¡ç”¨ **Zipformer** ä½œç‚º Speech Encoderï¼Œä¸¦çµåˆ **RWKV7** ä½œç‚º Language Modelã€‚

> [!IMPORTANT]  
> **ç ”ç©¶éšæ®µèªªæ˜**ï¼šæœ¬å°ˆæ¡ˆç›®å‰è™•æ–¼é–‹ç™¼èˆ‡å¯¦é©—éšæ®µï¼Œä¸»è¦ç›®çš„æ˜¯ç´€éŒ„å€‹äººå¯¦ä½œéç¨‹ã€‚ç¨‹å¼ç¢¼åƒè€ƒäº†å¤šå€‹é–‹æºå°ˆæ¡ˆï¼ˆå¦‚ NeMo, K2, RWKVï¼‰ï¼Œæ“·å–ç‰‡æ®µä¸¦é€²è¡Œç°¡åŒ–èˆ‡é‡çµ„ï¼Œæ—¨åœ¨æ‰“é€ ä¸€å€‹è¼•é‡ä¸”é«˜æ•ˆçš„ SpeechLLM æ¡†æ¶ï¼Œæ¯å€‹éƒ¨åˆ†æœƒå„æœ‰ä¸€å€‹ README ä¾†å¤§è‡´èªªæ˜å¯«æ³•ã€‚

---

## ğŸ—ï¸ ç³»çµ±æ¶æ§‹ (System Architecture)

* **Speech Encoder:** Zipformer (ä¾†è‡ª K2/Icefall)ï¼Œæä¾›é«˜æ•ˆçš„ä¸‹æ¡æ¨£èˆ‡ç‰¹å¾µæå–ã€‚
* **LLM Backbone:** RWKV7 ï¼Œçµåˆ RNN çš„æ¨ç†æ•ˆç‡èˆ‡ Transformer çš„è¨“ç·´è¡¨ç¾ã€‚
* **Data Pipeline:** åŸºæ–¼ Lhotse çš„å‹•æ…‹åˆ†æ¡¶ (Dynamic Bucketing) ç³»çµ±ã€‚

---

## ğŸš€ é–‹ç™¼é€²åº¦èˆ‡è·¯ç·šåœ– (Roadmap)

ç›®å‰çš„ç¨‹å¼æ•´ç†é€²åº¦å¦‚ä¸‹ï¼ŒæŒçºŒæ›´æ–°ä¸­ï¼š

- [x] **Data Pipeline (Lhotse-based)**
    - [x] æ”¯æŒ NeMo æ ¼å¼ Manifest è®€å–ã€‚
    - [x] å¯¦ç¾ `DynamicBucketingSampler` å‹•æ…‹ Batch Size èª¿æ•´ã€‚
    - [x] æ•´åˆ `Cutset.mux` æ¬Šé‡åŒ–å¤šæ•¸æ“šæºæ··åˆã€‚
    - [x] åœ¨ç·šæ•¸æ“šå¢å¼· (Speed, Volume, Noise, SpecAugment)ã€‚
    - [x] test dataset code and `conf.yaml`.
    - [x] noise manifest prepare script.
- [X] **Model Architecture**
    - [X] Zipformer Encoder æ•´åˆ and test codeã€‚
    - [X] RWKV7 ä»¥åŠ peft æ•´åˆã€‚
- [ ] **Training Implementation**
    - [ ] PyTorch Lightning Training Moduleã€‚
- [ ] **Checkpoints & Evaluation**
    - [ ] æä¾›é è¨“ç·´æ¨¡å‹æ¬Šé‡ã€‚

---


<details>
<summary><h3> K2 å®‰è£æŒ‡å— </h3></summary>

## ç’°å¢ƒè¦æ±‚

- Python 3.10
- CUDA 12.8
- PyTorch 2.8

## å®‰è£æ­¥é©Ÿ

### 1. ä¸‹è¼‰ K2 whl

æ ¹æ“šä½ çš„ç’°å¢ƒé…ç½®ï¼Œå¾å®˜æ–¹ [K2 CUDA é é¢](https://k2-fsa.github.io/k2/cuda.html) ä¸‹è¼‰æ­£ç¢ºç‰ˆæœ¬çš„ whlï¼š

```bash
wget https://huggingface.co/csukuangfj/k2/resolve/main/ubuntu-cuda/k2-1.24.4.dev20250807+cuda12.8.torch2.8.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl
```

### 2. ä¿®å¾©ä¸‹è¼‰å¾Œçš„æ–‡ä»¶å

æœ‰æ™‚å€™ä¸‹è¼‰å®Œçš„æ–‡ä»¶åä¸­çš„ `+` è™Ÿæœƒè¢«è½‰æ›ç‚º `%2B`ï¼Œä½ éœ€è¦æ‰‹å‹•æ”¹å› `+`ï¼š

```bash
# å¦‚æœæ–‡ä»¶ååŒ…å« %2Bï¼Œå°‡å…¶æ”¹ç‚º +
# åŸæ–‡ä»¶å: k2-1.24.4.dev20250807%2Bcuda12.8.torch2.8.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl
# æ–°æ–‡ä»¶å: k2-1.24.4.dev20250807+cuda12.8.torch2.8.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl
```

### 3. å®‰è£ K2

ä½¿ç”¨ `uv pip` å®‰è£ä¸‹è¼‰å¥½çš„ whlï¼š

```bash
uv pip install "k2-1.24.4.dev20250807+cuda12.8.torch2.8.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl"
```
</details>

## Zipformer speech encoder

æœ¬é …ç›®ä½¿ç”¨ [`AudenAI/auden-encoder-tta-m10`](https://huggingface.co/AudenAI/auden-encoder-tta-m10)ã€‚

<details>
<summary><h3> LLM-Based ASRï¼šéŸ³é »èˆ‡æ–‡æœ¬åµŒå…¥èåˆæ¦‚å¿µ </h3></summary>

## æ ¸å¿ƒæ¦‚å¿µ

![merge_features](./images/merge_features.jpg)

### æ¦‚å¿µ 1ï¼šéŸ³é »ä¸‹æ¡æ¨£èˆ‡ token å°é½Š

**ç·¨ç¢¼å™¨è¼¸å‡ºåˆ° token**

åœ¨éŸ³é »ç·¨ç¢¼ï¼ˆFbank â†’ ç·¨ç¢¼å™¨ï¼‰å¾Œï¼Œç·¨ç¢¼å™¨è¼¸å‡ºç‰¹å¾µé€šé**æŠ•å½±å±¤**é€²è¡Œä¸‹æ¡æ¨£ï¼š

- **ç·¨ç¢¼å™¨è¼¸å‡ºå½¢ç‹€**ï¼š`(B, T, encoder_out_dim)`ï¼Œå…¶ä¸­ T = éŸ³é »ç§’æ•¸ Ã— 25
- **æŠ•å½±å±¤ä¸‹æ¡æ¨£å¾Œ**ï¼š`(B, T//2, lim_dim)`
- **æ™‚é–“è§£æåº¦**ï¼šç´„ 12.5 Hz
  - æ¯å€‹ token ä»£è¡¨ **80ms** çš„éŸ³é »
  - **ä¸€å€‹ä¸­æ–‡å­—æŒçºŒæ™‚é–“**ï¼š0.2~0.3 ç§’
  - **æ¯å€‹å­—çš„ token**ï¼š2~4 å€‹ token


### æ¦‚å¿µ 2ï¼šæç¤ºè©è¨­è¨ˆèˆ‡ LLM å…¼å®¹æ€§

**ç‰¹å®šæ–¼æ¨¡å‹çš„æç¤ºè©æ ¼å¼**

ä¸åŒçš„é è¨“ç·´ LLM æ¨¡å‹éœ€è¦ä¸åŒçš„æç¤ºè©çµæ§‹ï¼Œé€™äº›çµæ§‹åœ¨è¨“ç·´æ™‚å·²ç¶“å®šç¾©ï¼š

- **RWKV7**ï¼šç°¡å–®æ ¼å¼ï¼Œå¦‚ `User: ` å’Œ `Assistant:`
- **Qwen**ï¼šç‰¹æ®Š tokenï¼Œå¦‚ `<|im_start|>` å’Œ `<|im_end|>`
- **ASR ç‰¹å®šæç¤ºè©**ï¼šå¸¸è¦‹çš„ä¸­æ–‡æç¤ºè©åŒ…æ‹¬ã€Œè«‹è½‰éŒ„é€™æ®µ{lang}èªéŸ³ã€

è£œå……ä¿¡æ¯ï¼šä¸€äº›è«–æ–‡ä¹Ÿæå‡ºäº†æç¤ºè©æŠ•å½±æ¨¡å¡Šä¾†è§£æ±ºæç¤ºè©çš„å½±éŸ¿ã€‚[Reducing Prompt Sensitivity in LLM-based Speech Recognition Through Learnable Projection](https://arxiv.org/html/2601.20898v1)

**æç¤ºè©æŠ•å½±æ¨¡å¡Šæ›¿ä»£æ–¹æ¡ˆ**

[è¿‘æœŸè«–æ–‡](https://arxiv.org/html/2409.19510v2)æå‡ºä½¿ç”¨æ›´ç°¡å–®çš„æ–¹æ³•åœ¨å¯¦è¸ä¸­ä¹Ÿæ•ˆæœå¾ˆå¥½ï¼š

- ç°¡å–®çš„ç‰¹æ®Š tokenï¼Œå¦‚ `<|en|>`ï¼ˆæˆ–ä¸­æ–‡çš„ `<|zh|>`ï¼‰é€šå¸¸å°±è¶³å¤ äº†
- é€™ç¨®è¼•é‡ç´šæ–¹æ³•é™ä½äº†è¨ˆç®—é–‹éŠ·ï¼ŒåŒæ™‚ä¿æŒäº†æœ‰æ•ˆæ€§
- èªè¨€è¦ç¯„å¹«åŠ©æ¨¡å‹é©ç•¶èª¿æ•´å…¶è§£ç¢¼ç­–ç•¥

### æ¦‚å¿µ 3ï¼šèåˆèˆ‡ LLM å‰å‘å‚³é

**åµŒå…¥æ‹¼æ¥ç­–ç•¥**

æ•´å€‹ç³»çµ±çš„é—œéµæ˜¯ç°¡å–®çš„æ‹¼æ¥ï¼š

1. **ä¸‹æ¡æ¨£çš„éŸ³é »ç‰¹å¾µ**ï¼šå½¢ç‹€ `(B, T//2, lim_dim)`
2. **æ–‡æœ¬ embeddings**ï¼šVarious prompt tokens and assistant markers
3. **æ‹¼æ¥**ï¼šå°‡éŸ³é »ç‰¹å¾µæ”¾åœ¨ `User: ` embeddings çš„å¾Œé¢
4. **åˆä½µè¼¸å…¥**ï¼š`[User_emb] + [Audio_tokens] + [Assistant_emb] + [Label_emb]`ï¼Œç¸½å½¢ç‹€ç‚º `(B, seq_len, lim_dim)`

**è¨“ç·´ vs. æ¨ç†çš„å€åˆ¥**

- **è¨“ç·´**ï¼š
  - æ‹¼æ¥æ©˜è‰²éƒ¨åˆ† + ç¶ è‰²éƒ¨åˆ†
  - å°‡æ•´å€‹åºåˆ—é€å…¥ LLM é€²è¡Œå‰å‘å‚³é
  - è¨ˆç®—ç¶ è‰²éƒ¨åˆ†çš„æå¤±ä»¥è¨“ç·´æ¨¡å‹

- **æ¨ç†**ï¼š
  - åªéœ€è¦æ©˜è‰²éƒ¨åˆ†
  - ç¶ è‰²éƒ¨åˆ†ç”± LLM çš„è‡ªè¿´æ­¸è§£ç¢¼ç”Ÿæˆ
  - ç„¡éœ€åœ¨æ¨ç†æ™‚æä¾›ç›®æ¨™æ–‡æœ¬



## ç¸½çµ

é€™ç¨®æ–¹æ³•çš„å„ªé›…ä¹‹è™•åœ¨æ–¼å…¶ç°¡æ½”æ€§ï¼š

1. **ä¸‹æ¡æ¨£**ç”Ÿæˆè‡ªç„¶å°é½Šçš„ tokenï¼ˆæ¯å€‹ç´„ 80msï¼‰ï¼Œèˆ‡éŸ³ç´ å–®ä½ç›¸å°æ‡‰
2. **æç¤ºè©è¨­è¨ˆ**ç°¡æ½”æ˜äº†ä¸”ä¾è³´æ–¼æ¨¡å‹ï¼›èªè¨€æ¨™è­˜ç¬¦å°±è¶³å¤ äº†
3. **èåˆ**åªæ˜¯æŒ‰ç‰¹å®šé †åºæ‹¼æ¥ embeddings
4. **è¨“ç·´/æ¨ç†ä¸å°ç¨±æ€§**åˆ©ç”¨äº† LLM å›ºæœ‰çš„è‡ªè¿´æ­¸æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›

é€šéå°‡ä¸‹æ¡æ¨£çš„éŸ³é »ç‰¹å¾µèˆ‡ç²¾å¿ƒæ ¼å¼åŒ–çš„æ–‡æœ¬æç¤ºç›¸çµåˆï¼Œè©²ç³»çµ±ä½¿ LLM èƒ½å¤ åœ¨æ²’æœ‰è¤‡é›œæ¶æ§‹ä¿®æ”¹çš„æƒ…æ³ä¸‹åŸ·è¡Œæœ‰æ•ˆçš„ç«¯åˆ°ç«¯ ASRã€‚

</details>

## ğŸ™ Acknowledgements
We borrowed a lot of code from the following excellent projects:
- [rkwv7](https://github.com/BlinkDL/RWKV-LM)
- [rwkv_asr](https://huggingface.co/yueyulin/rwkv_asr)
- [speechllm](https://github.com/zhu-han/SpeechLLM)
- [Auden](https://github.com/AudenAI/Auden)
- [Zipformer_Lightning](https://github.com/ZQuang2202/Zipformer_Lightning)
- [icefall](https://github.com/k2-fsa/icefall)
- [RWKV-PEFT](https://github.com/Joluck/RWKV-PEFT)